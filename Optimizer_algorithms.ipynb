{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM5ie4HMk3EtNnCrVhBzxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaolcay/Traditional-Machine-Learning-Techniques/blob/main/Optimizer_algorithms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Optimization Algorithms in Model Learning**\n",
        "Different optimizer algorithms in deep learning are used to update the model parameters (such as weight and bias terms and more) during the training process in order to minimize the loss function. There are some commonly used optimization methods, which will be shown how to implement in this tutorial, are listed below:\n",
        "\n",
        "1.   **Gradient Descent:** It is a basic optimization algorithm that updates the model parameters in the opposite direction of the gradient of the loss function. It can be further divided into variants such as Batch Gradient Descent, Mini-batch Gradient Descent, and Stochastic Gradient Descent (SGD), which randomly selects a single data point to compute the gradient.\n",
        "  *   **Batch Gradient Descent:** The number of examples used from training dataset to train the model is equal to the number of total examples.\n",
        "  *   **Stochastic Gradient Descent:** The number of examples used from training dataset to train the model is only 1.\n",
        "  *   **Mini-batch Gradient Descent:** The number of examples used from training dataset to train the model is between 1 and total number of examples in training dataset.\n",
        "\n",
        "2.   **Gradient Descent with Momentum:** Momentum is an extension of gradient descent that incorporates a momentum term in the update rule. It accumulates gradients over time and utilizes the accumulated gradient to update the parameters. This accelerates convergence, particularly in regions with high curvature, as it largely avoids having large steps in the vertical direction. In Gradient Descent with Momentum, a weighted moving average is employed to accumulate previous gradients. It introduces a momentum term that governs the impact of prior gradients on the current update. The weighted moving average is updated by calculating a weighted average of the current gradient and the previous weighted moving average.\n",
        "\n",
        "3. **RMSProp:** RMSProp (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm. In RMSProp, the weighted moving average is used to estimate the variance of the gradients. It maintains a separate exponentially decaying average of squared gradients. This average is then used to normalize the gradients by dividing them by the square root of the average.\n",
        "\n",
        "4. **Adam:** Adam extends RMSProp by incorporating momentum. It uses weighted moving averages to track both the first-order moment (mean) and the second-order moment (variance) of the gradients. These averages are then used to compute adaptive learning rates for each parameter.\n",
        "\n",
        "*Note that, in all these optimization methods, the weighted moving average helps to smooth out the noise in the gradients and provide a more stable estimation of the gradient statistics. By incorporating the weighted moving average, these algorithms can improve convergence speed, handle noisy gradients, and adaptively adjust the learning rates during the training process.*\n",
        "\n"
      ],
      "metadata": {
        "id": "9TxEszaFD-V9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**The Mathematical Expressions of Optimizer Algorithms**\n",
        "\n",
        "-> **Gradient Descent:**\n",
        "\n",
        "**Batch Gradient Descent:** \n",
        "  \n",
        "  $\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta)$\n",
        "\n",
        "**Stochastic Gradient Descent:** \n",
        "\n",
        "  $\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta;x^{(i)}, y^{(i)})$\n",
        "\n",
        "**Mini-batch Gradient Descent:** \n",
        "\n",
        "  $\\theta = \\theta - \\alpha \\cdot \\nabla J(\\theta;x^{(i:i+b)}, y^{(i:i+b)})$\n",
        "\n",
        "-> **Gradient Descent with Momentum:** \n",
        "\n",
        "  $v = \\beta \\cdot v + (1 - \\beta) \\cdot \\nabla J(\\theta)$\n",
        "\n",
        "  $\\theta = \\theta - \\alpha \\cdot v$\n",
        "\n",
        "-> **RMSProp:** \n",
        "\n",
        "  $s = \\beta \\cdot s + (1 - \\beta) \\cdot (\\nabla J(\\theta))^2$\n",
        "\n",
        "  $\\theta = \\theta - \\frac{\\alpha}{\\sqrt{s + \\epsilon}} \\cdot \\nabla J(\\theta)$\n",
        "\n",
        "\n",
        "-> **Adam:**\n",
        "\n",
        "  $v = \\beta_1 \\cdot v + (1 - \\beta_1) \\cdot \\nabla J(\\theta)$\n",
        "\n",
        "  $s = \\beta_2 \\cdot s + (1 - \\beta_2) \\cdot (\\nabla J(\\theta))^2$\n",
        "\n",
        "  $v_{\\text{corrected}} = \\frac{v}{1 - \\beta_1^t}$\n",
        "\n",
        "  $s_{\\text{corrected}} = \\frac{s}{1 - \\beta_2^t}$\n",
        "\n",
        "  $\\theta = \\theta - \\frac{\\alpha}{\\sqrt{s_{\\text{corrected}} + \\epsilon}} \\cdot v_{\\text{corrected}}$\n",
        "\n",
        "\n",
        "**Note:** The symbols used in the expressions are as follows:\n",
        "\n",
        "\n",
        "*   $\\theta$ represents the model parameters (weights and biases)\n",
        "*   $\\alpha$ denotes the learning rate\n",
        "*   $J(\\theta)$ represents the cost function\n",
        "*   $\\nabla J(\\theta)$ denotes the gradient of the cost function with respect to the parameters\n",
        "*   $x$ and $y$ represent the input features and corresponding labels, respectively\n",
        "*   $v$ denotes the velocity term in momentum-based optimization algorithms\n",
        "*   $s$ represents the exponentially weighted average of squared gradients in RMSProp and Adam\n",
        "*   $\\beta_1$ and $\\beta_2$ are the exponential decay rates for the moment estimates in Adam\n",
        "*   $t$ represents the iteration or time step\n",
        "*   $\\epsilon$ is a small value added for numerical stability.\n"
      ],
      "metadata": {
        "id": "EOP9FKNSKIuR"
      }
    }
  ]
}